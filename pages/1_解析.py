# -*- coding: utf-8 -*-
# pages/1_è§£æ.py

import os, json
import streamlit as st

# ========= è§£æãƒ­ã‚¸ãƒƒã‚¯ï¼ˆUIã‚ˆã‚Šä¸Šã«ç½®ãï¼‰ =========

SOFT_CUES = {
    "confirmation": ["ç¢ºä¿¡", "é–“é•ã„ãªã„", "çµ¶å¯¾", "éƒ½åˆã®è‰¯ã„", "è¦‹ãŸã„ã‚‚ã®ã ã‘"],
    "sunk_cost": ["ã›ã£ã‹ã", "ã“ã“ã¾ã§ã‚„ã£ãŸ", "å…ƒã‚’å–ã‚‹", "ã‚‚ã£ãŸã„ãªã„"],
    "loss_aversion": ["æã—ãŸããªã„", "ç„¡é§„", "å¾Œæ‚”"],
    "availability": ["ã‚ˆãèã", "ã¿ã‚“ãªè¨€ã£ã¦ã‚‹", "SNSã§è¦‹ãŸ", "ãƒã‚ºã£ã¦ã‚‹"],
    "framing": ["ãŠå¾—", "é™å®š", "ä»Šã ã‘", "å…ˆç€"],
}

EMOTION_WORDS = ["ä¸å®‰", "ç„¦ã‚Š", "ãƒ¯ã‚¯ãƒ¯ã‚¯", "æ€–ã„", "å¬‰ã—ã„", "æ‚”ã—ã„", "æ€’ã‚Š", "ç·Šå¼µ"]

def load_rules() -> dict:
    default_rules = {
        "confirmation": {
            "label": "ç¢ºè¨¼ãƒã‚¤ã‚¢ã‚¹",
            "explain": "è‡ªåˆ†ã®è€ƒãˆã«åˆã†æƒ…å ±ã°ã‹ã‚Šã‚’é›†ã‚ã€åå¯¾ã®æ„è¦‹ã‚’ç„¡è¦–ã—ã¦ã—ã¾ã†æ€è€ƒã®ãã›ã€‚",
            "keywords": ["è‡ªåˆ†ã®è€ƒãˆã«åˆã†", "éƒ½åˆãŒè‰¯ã„", "åå¯¾ã®æƒ…å ±ã‚’ç„¡è¦–"],
            "interventions": [
                "åå¯¾ã®è¨¼æ‹ ã‚’æœ€ä½1ã¤æ¢ã—ã¦ã¿ã‚ˆã†",
                "ç«‹å ´ãŒé€†ã®äººã«ãªã‚Šãã£ã¦ä¸»å¼µã‚’æ›¸ã„ã¦ã¿ã‚ˆã†",
            ],
        },
        "sunk_cost": {
            "label": "ã‚µãƒ³ã‚¯ã‚³ã‚¹ãƒˆã®èª¤è¬¬",
            "explain": "ã“ã‚Œã¾ã§ä½¿ã£ãŸæ™‚é–“ã‚„ãŠé‡‘ãŒã‚‚ã£ãŸã„ãªãã¦ã€ç¶šã‘ã‚‹ã‹è¿·ã†å¿ƒç†ã€‚",
            "keywords": ["ã“ã“ã¾ã§æŠ•è³‡", "ã‚‚ã£ãŸã„ãªã„", "å…ƒã‚’å–ã‚‹"],
            "interventions": [
                "ä»Šã‹ã‚‰å§‹ã‚ã‚‹ã¨ã—ã¦ã‚‚åŒã˜åˆ¤æ–­ã‚’ã™ã‚‹ã‹ï¼Ÿã‚’è€ƒãˆã¦ã¿ã‚ˆã†",
                "æœªæ¥ã®åˆ©ç›Šã ã‘ã§åˆ¤æ–­ã—ã¦ã¿ã‚ˆã†",
            ],
        },
        "loss_aversion": {
            "label": "æå¤±å›é¿ãƒã‚¤ã‚¢ã‚¹",
            "explain": "å¾—ã‚’ã™ã‚‹ã‚ˆã‚Šã‚‚ã€æã‚’ã—ãŸããªã„æ°—æŒã¡ã®ã»ã†ãŒå¼·ããªã‚‹å¿ƒç†ã€‚",
            "keywords": ["æã—ãŸããªã„", "å¤±ã†", "ç„¡é§„ã«ãªã‚‹"],
            "interventions": [
                "å¤±ã†ã‚‚ã®ã¨å¾—ã‚‰ã‚Œã‚‹ã‚‚ã®ã‚’ä¸¦ã¹ã¦æ¯”ã¹ã¦ã¿ã‚ˆã†",
                "ç›®çš„ï¼ˆä½•ã®ãŸã‚ï¼Ÿï¼‰ã‚’æ€ã„å‡ºã—ã¦åˆ¤æ–­ã—ã‚ˆã†",
            ],
        },
        "availability": {
            "label": "åˆ©ç”¨å¯èƒ½æ€§ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯",
            "explain": "ã‚ˆãèãè©±ã‚„æœ€è¿‘è¦‹ãŸæƒ…å ±ã»ã©ã€ã€æ­£ã—ã„ã€ã¨æ„Ÿã˜ã¦ã—ã¾ã†æ€ã„è¾¼ã¿ã€‚",
            "keywords": ["ã‚ˆãèã", "SNSã§è¦‹ãŸ", "è©±é¡Œ"],
            "interventions": [
                "SNSã§ã¯ãªãä¸€æ¬¡æƒ…å ±ï¼ˆå…¬å¼ã‚µã‚¤ãƒˆãªã©ï¼‰ã‚’1ã¤ç¢ºèªã—ã¦ã¿ã‚ˆã†",
                "æœ€è¿‘ã®è©±é¡Œã¨å®Ÿéš›ã®ç¢ºç‡ã‚’åŒºåˆ¥ã—ã¦è€ƒãˆã‚ˆã†",
            ],
        },
        "framing": {
            "label": "ãƒ•ãƒ¬ãƒ¼ãƒŸãƒ³ã‚°åŠ¹æœ",
            "explain": "åŒã˜å†…å®¹ã§ã‚‚ã€ãŠå¾—ï¼ã€ã€ä»Šã ã‘ï¼ã€ãªã©ã®è¨€ã„æ–¹ã§åˆ¤æ–­ãŒå¤‰ã‚ã‚‹å¿ƒç†ã€‚",
            "keywords": ["ãŠå¾—", "å‰²å¼•", "é™å®š", "ä»Šã ã‘", "å…ˆç€"],
            "interventions": [
                "åˆ¥ã®è¡¨ç¾ï¼ˆæã‚’ã™ã‚‹ï¼å¾—ã‚’ã™ã‚‹ï¼‰ã«è¨€ã„æ›ãˆã¦æ¯”ã¹ã¦ã¿ã‚ˆã†",
                "é•·æœŸçš„ãªã‚³ã‚¹ãƒˆã‚„ãƒªã‚¹ã‚¯ã‚’è¦‹ç›´ãã†",
            ],
        },
    }

    try:
        with open(os.path.join(os.getcwd(), "rules.json"), encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return default_rules

RULES = load_rules()

def analyze_text(text: str, rules: dict, sensitivity: int):
    text = (text or "").strip()
    if not text:
        return [], {}
    threshold = 1.20 - (sensitivity / 100) * 0.80
    findings, debug_scores = [], {}

    for key, spec in rules.items():
        score, evidences = 0.0, []

        for kw in spec.get("keywords", []):
            if kw and kw in text:
                score += 1.0
                evidences.append(kw)
        for soft_kw in SOFT_CUES.get(key, []):
            if soft_kw and soft_kw in text:
                score += 0.5
                evidences.append(soft_kw)

        if score >= threshold:
            conf = "A" if score >= (threshold + 0.8) else "B"
            findings.append({
                "type": key,
                "label": spec.get("label", key),
                "explain": spec.get("explain", ""),
                "confidence": conf,
                "evidence": evidences,
                "suggestions": spec.get("interventions", []),
                "score": round(score, 2),
            })
        debug_scores[spec.get("label", key)] = round(score, 2)

    emo_hits = [w for w in EMOTION_WORDS if w in text]
    emo_score = 0.5 * len(emo_hits)
    if emo_score >= max(0.5, threshold * 0.6):
        findings.append({
            "type": "affect",
            "label": "æ„Ÿæƒ…ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯",
            "explain": "ä¸å®‰ãƒ»ç„¦ã‚Šãƒ»å¬‰ã—ã•ãªã©ã®æ„Ÿæƒ…ãŒåˆ¤æ–­ã‚’å·¦å³ã—ã¦ã—ã¾ã†å¿ƒç†ã€‚",
            "confidence": "B" if emo_score < (threshold + 0.8) else "A",
            "evidence": emo_hits,
            "suggestions": [
                "ä¸€æ™©ãŠã„ã¦ã‹ã‚‰å†è©•ä¾¡ï¼ˆ24æ™‚é–“ãƒ«ãƒ¼ãƒ«ï¼‰",
                "ç¬¬ä¸‰è€…ã®çŸ­è©•ï¼ˆå¤–éƒ¨è¦–ç‚¹ï¼‰ã‚’3è¡Œã§ã‚‚ã‚‰ã†",
            ],
            "score": round(emo_score, 2),
        })
    debug_scores["æ„Ÿæƒ…ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯"] = round(emo_score, 2)

    findings.sort(key=lambda x: x.get("score", 0.0), reverse=True)
    return findings, {"threshold": round(threshold, 2), "scores": debug_scores}

# ========= UI =========

st.set_page_config(page_title="ãƒã‚¤ã‚¢ã‚¹è§£æã‚¢ãƒ—ãƒª", layout="centered", initial_sidebar_state="collapsed")

# ãƒ¢ãƒã‚¤ãƒ«ã«æœ€é©åŒ–ã—ãŸè»½CSS
st.markdown("""
<style>
h1 {text-align:center;font-size:1.5rem;margin-bottom:0.3rem;}
h2, h3 {font-size:1.1rem;margin-top:1.1rem;margin-bottom:0.3rem;}
.small {color:#666;font-size:0.9rem;text-align:center;margin-bottom:0.5rem;}
.result-card {border:1px solid #eaeaea;border-radius:10px;padding:0.8rem;margin-bottom:0.6rem;background:#fdfdff;}
.badge {display:inline-block;padding:.1rem .4rem;border-radius:999px;background:#eef;margin-left:.3rem;font-size:0.8rem;}
.explain {font-size:0.9rem;color:#444;margin-bottom:0.4rem;}
</style>
""", unsafe_allow_html=True)

st.markdown("<h1>ğŸ§  ãƒã‚¤ã‚¢ã‚¹è§£æã‚¢ãƒ—ãƒª</h1>", unsafe_allow_html=True)
st.markdown('<div class="small">Self-Bias Monitor (é«˜æ ¡ç”Ÿã§ã‚‚ä½¿ã„ã‚„ã™ã„)</div>', unsafe_allow_html=True)

# --- è¨­å®š ---
with st.expander("è¨­å®šï¼ˆä»»æ„ï¼‰", expanded=False):
    sensitivity = st.slider("æ¤œå‡ºã®æ•æ„Ÿã•ï¼ˆé«˜ã„ã»ã©æ‹¾ã„ã‚„ã™ã„ï¼‰", 0, 100, 50)
    st.session_state["sensitivity"] = sensitivity

# --- å…¥åŠ› ---
st.markdown("### ä»Šæ—¥ã®æ„æ€æ±ºå®šï¼ˆå…¥åŠ›ï¼‰")
text = st.text_area("ä»Šæ—¥ã€ã‚ãªãŸãŒè¿·ã£ã¦ã„ã‚‹ã“ã¨ã‚„æ±ºã‚ãŸã„ã“ã¨ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚", height=150)

# --- è§£æ ---
if st.button("ãƒã‚¤ã‚¢ã‚¹ã‚’è§£æã™ã‚‹", type="primary", use_container_width=True):
    if not text.strip():
        st.warning("å…¥åŠ›ãŒç©ºã§ã™ã€‚å†…å®¹ã‚’è¨˜å…¥ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("è€ƒãˆæ–¹ã‚’ãƒã‚§ãƒƒã‚¯ä¸­..."):
            findings, debug = analyze_text(text, RULES, st.session_state.get("sensitivity", 50))
        st.session_state["result"] = {"findings": findings, "debug": debug, "text": text}

if "result" in st.session_state:
    res = st.session_state["result"]
    st.divider()
    st.markdown("### è§£æçµæœ")
    if not res["findings"]:
        st.info("ç‰¹ã«å¼·ã„ãƒã‚¤ã‚¢ã‚¹ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ãƒãƒ©ãƒ³ã‚¹ã®è‰¯ã„åˆ¤æ–­ã§ã™ã€‚")
    else:
        for f in res["findings"]:
            st.markdown(f"""
            <div class="result-card">
                <h4>{f["label"]}
                    <span class="badge">ä¿¡é ¼åº¦: {f["confidence"]}</span>
                    <span class="badge">ã‚¹ã‚³ã‚¢: {f["score"]}</span>
                </h4>
                <div class="explain">{f["explain"]}</div>
                <b>æ ¹æ‹ :</b> {'ã€'.join(f["evidence"]) if f["evidence"] else 'ãªã—'}<br>
                <b>å¯¾ç­–ã®ãƒ’ãƒ³ãƒˆ:</b>
            </div>
            """, unsafe_allow_html=True)
            for tip in f["suggestions"]:
                st.write("ãƒ»" + tip)

    with st.expander("ã‚¹ã‚³ã‚¢è©³ç´°ï¼ˆä¸Šç´šè€…å‘ã‘ï¼‰"):
        st.write(res["debug"])

    if st.button("çµæœã‚’ã‚¯ãƒªã‚¢ã—ã¦ã‚„ã‚Šç›´ã™"):
        st.session_state.pop("result", None)
        st.rerun()
